{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2d0062",
   "metadata": {},
   "source": [
    "# 1.1 Загрузка и предварительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ae41e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      TIME    OPEN    MAX     MIN   CLOSE  VOLUME\n",
      "0  03.01.2002  11:00:00  373.00  374.5  373.00  374.50    5064\n",
      "1  03.01.2002  11:01:00  374.50  375.4  374.01  374.01    8450\n",
      "2  03.01.2002  11:02:00  374.12  375.2  374.10  374.65     507\n",
      "3  03.01.2002  11:03:00  374.65  375.0  374.03  375.00    1669\n",
      "4  03.01.2002  11:04:00  375.00  375.6  375.00  375.60    4000\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "239327  30.12.2003  18:40:00  678.01  678.01  677.80  677.80    1926\n",
      "239328  30.12.2003  18:41:00  677.80  677.90  677.80  677.80     451\n",
      "239329  30.12.2003  18:42:00  677.70  677.70  677.14  677.14     966\n",
      "239330  30.12.2003  18:43:00  677.17  677.79  677.13  677.14    1292\n",
      "239331  30.12.2003  18:44:00  677.10  677.10  674.53  677.00    8333\n",
      "         DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "0  05.01.2004  10:30:00  681.05  685.00  681.05  684.00    4833\n",
      "1  05.01.2004  10:31:00  684.79  688.00  684.01  686.00    7025\n",
      "2  05.01.2004  10:32:00  685.00  688.00  685.00  685.12    3956\n",
      "3  05.01.2004  10:33:00  686.98  687.00  686.02  686.02    1105\n",
      "4  05.01.2004  10:34:00  687.00  688.68  687.00  688.00    6270\n",
      "              DATE      TIME    OPEN      MAX      MIN   CLOSE  VOLUME\n",
      "246010  29.12.2005  18:40:00  1704.0  1706.97  1704.00  1705.9    6744\n",
      "246011  29.12.2005  18:41:00  1705.9  1707.87  1705.90  1707.0    9604\n",
      "246012  29.12.2005  18:42:00  1707.0  1707.00  1705.99  1707.0    2869\n",
      "246013  29.12.2005  18:43:00  1706.0  1706.99  1705.70  1705.7    1766\n",
      "246014  29.12.2005  18:44:00  1706.0  1706.96  1704.00  1704.0    3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      TIME     OPEN     MAX     MIN    CLOSE  VOLUME\n",
      "0  10.01.2006  10:30:00  1801.00  1815.0  1800.0  1801.01    7610\n",
      "1  10.01.2006  10:31:00  1809.01  1810.0  1791.5  1800.00   10928\n",
      "2  10.01.2006  10:32:00  1800.00  1800.0  1789.0  1789.00   27916\n",
      "3  10.01.2006  10:33:00  1787.17  1790.0  1777.0  1780.09   38418\n",
      "4  10.01.2006  10:34:00  1781.00  1785.0  1778.0  1785.00   30355\n",
      "              DATE      TIME     OPEN      MAX      MIN    CLOSE  VOLUME\n",
      "233260  28.12.2007  17:40:00  2080.01  2080.50  2078.12  2078.12   12008\n",
      "233261  28.12.2007  17:41:00  2079.00  2079.01  2074.00  2074.00   29324\n",
      "233262  28.12.2007  17:42:00  2074.00  2078.15  2074.00  2075.01   16791\n",
      "233263  28.12.2007  17:43:00  2076.98  2077.00  2071.33  2071.33   18922\n",
      "233264  28.12.2007  17:44:00  2075.00  2075.00  2067.10  2067.10   13368\n",
      "         DATE      TIME     OPEN      MAX      MIN    CLOSE  VOLUME\n",
      "0  09.01.2008  10:30:00  2081.00  2086.99  2081.00  2086.99    3605\n",
      "1  09.01.2008  10:31:00  2087.00  2087.00  2082.01  2084.90    5392\n",
      "2  09.01.2008  10:32:00  2083.00  2089.00  2082.01  2088.00   18646\n",
      "3  09.01.2008  10:33:00  2088.01  2088.01  2081.00  2081.00    8556\n",
      "4  09.01.2008  10:34:00  2081.00  2083.96  2081.00  2081.11    2055\n",
      "              DATE      TIME     OPEN      MAX      MIN    CLOSE  VOLUME\n",
      "233051  30.12.2009  18:40:00  1694.01  1694.01  1691.10  1691.10    9994\n",
      "233052  30.12.2009  18:41:00  1691.10  1692.00  1689.00  1689.99    4003\n",
      "233053  30.12.2009  18:42:00  1689.97  1692.00  1689.03  1690.13    5533\n",
      "233054  30.12.2009  18:43:00  1690.13  1690.19  1688.00  1688.00   10897\n",
      "233055  30.12.2009  18:44:00  1689.92  1695.00  1688.00  1688.06   11267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      TIME     OPEN      MAX      MIN    CLOSE  VOLUME\n",
      "0  11.01.2010  10:30:00  1744.32  1749.00  1740.00  1743.00   14849\n",
      "1  11.01.2010  10:31:00  1743.01  1750.00  1742.13  1746.04   23797\n",
      "2  11.01.2010  10:32:00  1746.05  1750.00  1739.86  1739.86   17694\n",
      "3  11.01.2010  10:33:00  1740.01  1740.01  1736.80  1737.83    6207\n",
      "4  11.01.2010  10:34:00  1737.83  1740.26  1737.11  1739.00    3894\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "248095  30.12.2011  18:40:00  1708.0  1709.0  1705.1  1707.0    2427\n",
      "248096  30.12.2011  18:41:00  1707.0  1707.0  1704.5  1707.0    2797\n",
      "248097  30.12.2011  18:42:00  1706.4  1707.0  1704.6  1705.0    6248\n",
      "248098  30.12.2011  18:43:00  1705.0  1705.0  1700.0  1700.0   12592\n",
      "248099  30.12.2011  18:44:00  1699.3  1703.1  1699.0  1701.0    5371\n",
      "         DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "0  03.01.2012  10:00:00  1712.0  1719.8  1712.0  1718.2    4946\n",
      "1  03.01.2012  10:01:00  1718.2  1720.0  1717.0  1719.6    1643\n",
      "2  03.01.2012  10:02:00  1719.8  1720.0  1717.5  1718.2     804\n",
      "3  03.01.2012  10:03:00  1718.2  1719.2  1717.4  1719.2    2228\n",
      "4  03.01.2012  10:04:00  1719.2  1720.0  1719.2  1719.9    2086\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "264713  30.12.2013  18:35:00  2037.5  2037.7  2036.9  2037.7    2440\n",
      "264714  30.12.2013  18:36:00  2037.6  2040.0  2037.5  2039.6   10882\n",
      "264715  30.12.2013  18:37:00  2039.0  2039.3  2039.0  2039.2     721\n",
      "264716  30.12.2013  18:38:00  2039.1  2039.9  2038.4  2039.0    3215\n",
      "264717  30.12.2013  18:39:00  2039.6  2040.0  2039.0  2039.7    2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "0  06.01.2014  10:00:00  2017.9  2023.0  2015.2  2015.6    1211\n",
      "1  06.01.2014  10:01:00  2015.6  2018.6  2015.6  2018.0    2444\n",
      "2  06.01.2014  10:02:00  2016.2  2018.2  2012.3  2017.1     681\n",
      "3  06.01.2014  10:03:00  2017.1  2018.8  2010.2  2010.2    3377\n",
      "4  06.01.2014  10:04:00  2011.1  2014.0  2010.2  2014.0     759\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "261698  30.12.2015  18:39:00  2349.4  2354.8  2345.0  2354.8    6499\n",
      "261699  30.12.2015  18:45:00  2345.9  2345.9  2345.9  2345.9   25611\n",
      "261700  30.12.2015  18:46:00  2345.9  2345.9  2345.9  2345.9    2245\n",
      "261701  30.12.2015  18:47:00  2345.9  2345.9  2345.9  2345.9     155\n",
      "261702  30.12.2015  18:49:00  2345.9  2345.9  2345.9  2345.9    5335\n",
      "         DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "0  04.01.2016  10:00:00  2351.0  2355.8  2350.0  2350.0    2547\n",
      "1  04.01.2016  10:01:00  2352.9  2355.7  2350.0  2355.7     195\n",
      "2  04.01.2016  10:02:00  2355.6  2356.0  2351.4  2354.1     257\n",
      "3  04.01.2016  10:03:00  2354.5  2355.0  2351.2  2353.7     763\n",
      "4  04.01.2016  10:04:00  2353.1  2353.9  2353.1  2353.6     231\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "263920  29.12.2017  18:37:00  3320.5  3322.0  3316.5  3317.0    1227\n",
      "263921  29.12.2017  18:38:00  3318.0  3323.5  3317.0  3323.5     938\n",
      "263922  29.12.2017  18:39:00  3323.0  3324.0  3314.5  3314.5    1996\n",
      "263923  29.12.2017  18:45:00  3334.5  3334.5  3334.5  3334.5   83877\n",
      "263924  29.12.2017  18:49:00  3334.5  3334.5  3334.5  3334.5       2\n",
      "         DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "0  03.01.2018  10:00:00  3341.0  3356.0  3340.0  3355.0    6088\n",
      "1  03.01.2018  10:01:00  3355.0  3359.0  3353.0  3353.0    1624\n",
      "2  03.01.2018  10:02:00  3351.5  3357.5  3351.5  3357.5     722\n",
      "3  03.01.2018  10:03:00  3354.5  3360.0  3354.5  3358.0    3034\n",
      "4  03.01.2018  10:04:00  3358.0  3360.0  3351.5  3360.0    1427\n",
      "              DATE      TIME    OPEN     MAX     MIN   CLOSE  VOLUME\n",
      "217942  23.08.2019  18:45:00  5183.5  5183.5  5183.5  5183.5   31523\n",
      "217943  23.08.2019  18:46:00  5183.5  5183.5  5183.5  5183.5    5090\n",
      "217944  23.08.2019  18:47:00  5183.5  5183.5  5183.5  5183.5     230\n",
      "217945  23.08.2019  18:48:00  5183.5  5183.5  5183.5  5183.5       5\n",
      "217946  23.08.2019  18:49:00  5183.5  5183.5  5183.5  5183.5     994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\3937177094.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(d)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from pylab import rcParams\n",
    "df = pd.DataFrame()\n",
    "import os\n",
    "for i in os.listdir():\n",
    "    if (\"0\" or \"1\") and \"_\" and \".csv\" in i:\n",
    "        d = pd.read_csv(i, sep=\";\", parse_dates = True)\n",
    "        #print(\"Рассматриваем файл: \" + i, end=\"\\n\")\n",
    "        df = df.append(d)\n",
    "        print(d.head())\n",
    "        print(d.tail())\n",
    "        \n",
    "        #df = pd.read_csv(i, sep=\";\", parse_dates = True)\n",
    "        #df['Datetime'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'])\n",
    "        #df1 = df.copy()\n",
    "        #df1 = df1.set_index(keys=df1[\"DATE\"], drop=True)\n",
    "        #df1.sort_index(inplace=True)\n",
    "        #df1.index = pd.to_datetime(df1.index)\n",
    "        #df1.drop(columns=[\"DATE\", \"TIME\", \"OPEN\", \"MIN\", \"MAX\", \"Datetime\"], inplace=True)\n",
    "        #df1 = df1.groupby(df1.index.date).agg([\"mean\"])\n",
    "        #df1 = df1.asfreq(\"d\", method=\"ffill\")\n",
    "        #df1.sort_index(inplace=True)\n",
    "        #rcParams['figure.figsize'] = 11, 9\n",
    "        #decompose = seasonal_decompose(df1[\"CLOSE\"], model = 'additive')\n",
    "        #decompose.plot()\n",
    "        #x = [x for x in range(0,  df.shape[0] , 30)]\n",
    "        #plot_acf(df[\"CLOSE\"], lags=x)\n",
    "        #adf_test = adfuller(df[\"CLOSE\"])\n",
    "        #print('p-value = ' + str(adf_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424275f4",
   "metadata": {},
   "source": [
    "Как мы можем заметить, нам даны данные о стоимости акций поминутно во время торгов, стоимости акций во время открытия торгов, максимальной и минимальной стоимости акций во время торгов, стоимость акций на момент закрытия торгов, а также количество купленных/проданных акций во время торгов.\n",
    "\n",
    "Поскольку нам нужно предсказать стоимость, то логично, что стоимость во время открытия торгов приоритетна, потому что практически всегда стоимость во время закрытия = стоимости во время открытия, поэтому мы оставляем один из этих признаков.\n",
    "\n",
    "Все остальные признаки, кроме количества купленных/проданных акций и стоимости во время открытия торгов можно удалить, поскольку эти признаки являются несущественными, а кол-во купленных/проданных акций влияет напрямую на стоимость, поскольку если цена акций начинает расти, их больше начинают покупать, а если перестаёт расти или падает, то перестают покупать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9090df39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>373.00</td>\n",
       "      <td>374.5</td>\n",
       "      <td>373.00</td>\n",
       "      <td>374.50</td>\n",
       "      <td>5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>374.50</td>\n",
       "      <td>375.4</td>\n",
       "      <td>374.01</td>\n",
       "      <td>374.01</td>\n",
       "      <td>8450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>11:02:00</td>\n",
       "      <td>374.12</td>\n",
       "      <td>375.2</td>\n",
       "      <td>374.10</td>\n",
       "      <td>374.65</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>11:03:00</td>\n",
       "      <td>374.65</td>\n",
       "      <td>375.0</td>\n",
       "      <td>374.03</td>\n",
       "      <td>375.00</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03.01.2002</td>\n",
       "      <td>11:04:00</td>\n",
       "      <td>375.00</td>\n",
       "      <td>375.6</td>\n",
       "      <td>375.00</td>\n",
       "      <td>375.60</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217942</th>\n",
       "      <td>23.08.2019</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.5</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>31523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217943</th>\n",
       "      <td>23.08.2019</td>\n",
       "      <td>18:46:00</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.5</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217944</th>\n",
       "      <td>23.08.2019</td>\n",
       "      <td>18:47:00</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.5</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217945</th>\n",
       "      <td>23.08.2019</td>\n",
       "      <td>18:48:00</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.5</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217946</th>\n",
       "      <td>23.08.2019</td>\n",
       "      <td>18:49:00</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.5</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>5183.50</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208061 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE      TIME     OPEN     MAX      MIN    CLOSE  VOLUME\n",
       "0       03.01.2002  11:00:00   373.00   374.5   373.00   374.50    5064\n",
       "1       03.01.2002  11:01:00   374.50   375.4   374.01   374.01    8450\n",
       "2       03.01.2002  11:02:00   374.12   375.2   374.10   374.65     507\n",
       "3       03.01.2002  11:03:00   374.65   375.0   374.03   375.00    1669\n",
       "4       03.01.2002  11:04:00   375.00   375.6   375.00   375.60    4000\n",
       "...            ...       ...      ...     ...      ...      ...     ...\n",
       "217942  23.08.2019  18:45:00  5183.50  5183.5  5183.50  5183.50   31523\n",
       "217943  23.08.2019  18:46:00  5183.50  5183.5  5183.50  5183.50    5090\n",
       "217944  23.08.2019  18:47:00  5183.50  5183.5  5183.50  5183.50     230\n",
       "217945  23.08.2019  18:48:00  5183.50  5183.5  5183.50  5183.50       5\n",
       "217946  23.08.2019  18:49:00  5183.50  5183.5  5183.50  5183.50     994\n",
       "\n",
       "[2208061 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cb2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93506560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index(keys=df[\"Datetime\"], drop=True)\n",
    "df1.set_index(keys=df1.DATE, drop=True, inplace=True)\n",
    "df1.drop(columns=[\"DATE\", \"TIME\", \"OPEN\", \"MIN\", \"MAX\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e5e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13804\\1085943857.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df1.index = pd.to_datetime(df1.index)\n"
     ]
    }
   ],
   "source": [
    "df1.index = pd.to_datetime(df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073ffa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-02</th>\n",
       "      <td>434.813238</td>\n",
       "      <td>1380.278571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-03</th>\n",
       "      <td>387.911738</td>\n",
       "      <td>1983.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-04</th>\n",
       "      <td>453.656000</td>\n",
       "      <td>756.792857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-05</th>\n",
       "      <td>453.656000</td>\n",
       "      <td>756.792857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-06</th>\n",
       "      <td>453.656000</td>\n",
       "      <td>756.792857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>5606.358095</td>\n",
       "      <td>1161.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>5606.358095</td>\n",
       "      <td>1161.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>5606.358095</td>\n",
       "      <td>1161.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07</th>\n",
       "      <td>5246.689524</td>\n",
       "      <td>969.337143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08</th>\n",
       "      <td>5316.502857</td>\n",
       "      <td>1370.163810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6550 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CLOSE       VOLUME\n",
       "                   mean         mean\n",
       "2002-01-02   434.813238  1380.278571\n",
       "2002-01-03   387.911738  1983.757143\n",
       "2002-01-04   453.656000   756.792857\n",
       "2002-01-05   453.656000   756.792857\n",
       "2002-01-06   453.656000   756.792857\n",
       "...                 ...          ...\n",
       "2019-12-04  5606.358095  1161.971429\n",
       "2019-12-05  5606.358095  1161.971429\n",
       "2019-12-06  5606.358095  1161.971429\n",
       "2019-12-07  5246.689524   969.337143\n",
       "2019-12-08  5316.502857  1370.163810\n",
       "\n",
       "[6550 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.groupby(df1.index.date).agg([\"mean\"])\n",
    "df1 = df1.asfreq(\"d\", method=\"ffill\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42febda4",
   "metadata": {},
   "source": [
    "# 1.2 Анализ временных рядов\n",
    "## Анализ компонентов(шум, сезонность, тренд)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac65666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1.sort_index(inplace=True)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 11, 9\n",
    "decompose = seasonal_decompose(df1[\"CLOSE\"][:1000], model = 'additive')\n",
    "decompose.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c386e0",
   "metadata": {},
   "source": [
    "## Исследование временного ряда на наличие автокорреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x in range(0,  df.shape[0] , 21000)]\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(df[\"CLOSE\"], lags=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef358e4",
   "metadata": {},
   "source": [
    "Ряд имеет автокорреляцию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079385f9",
   "metadata": {},
   "source": [
    "## Исследование временного ряда на стационарность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1316f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(df[\"CLOSE\"])\n",
    "print('p-value = ' + str(adf_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de6fa5",
   "metadata": {},
   "source": [
    "Поскольку значение очень мало, то можно сделать вывод, что временной ряд стационарен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909050ec",
   "metadata": {},
   "source": [
    "# 2.1 Формирование и подготовка данных для обучения нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10334ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {}\n",
    "for x in df.columns:\n",
    "    scalers[x] = StandardScaler().fit(df[x].values.reshape(-1, 1))\n",
    "\n",
    "norm_df = df.copy()\n",
    "for i, key in enumerate(scalers.keys()):\n",
    "    norm = scalers[key].transform(norm_df.iloc[:, i].values.reshape(-1, 1))\n",
    "    norm_df.iloc[:, i] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e85750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datetime import date, datetime\n",
    "import os\n",
    "def generate_sequences(df: pd.DataFrame, tw: int, pw: int, target_columns, drop_targets=False):\n",
    "    data = dict()\n",
    "    L = len(df)\n",
    "    for i in range(L-tw):\n",
    "        if drop_targets:\n",
    "            df.drop(target_columns, axis=1, inplace=True)\n",
    "        sequence = df[i:i+tw].values\n",
    "        target = df[i+tw:i+tw+pw][target_columns].values\n",
    "        data[i] = {'sequence': sequence, 'target': target}\n",
    "    return data\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return torch.Tensor(sample['sequence']), torch.Tensor(sample['target'])\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "nhid = 50\n",
    "nout = 1\n",
    "sequence_len = 180\n",
    "n_dnn_layers = 5\n",
    "ninp = 1\n",
    "split = 0.8\n",
    "\n",
    "sequences = generate_sequences(norm_df.Australia.to_frame(), sequence_len, nout, 'Australia')\n",
    "dataset = SequenceDataset(sequences)\n",
    "\n",
    "train_len = int(len(dataset)*split)\n",
    "lens = [train_len, len(dataset)-train_len]\n",
    "train_ds, test_ds = random_split(dataset, lens)\n",
    "trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4d13b",
   "metadata": {},
   "source": [
    "# 2.1 Моделирование и построение прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_features, n_hidden, n_outputs, sequence_len, n_lstm_layers=1, n_deep_layers=10, use_cuda=False, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        self.nhid = n_hidden\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.lstm = nn.LSTM(n_features,\n",
    "                            n_hidden,\n",
    "                            num_layers=n_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(n_hidden * sequence_len, n_hidden) \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        dnn_layers = []\n",
    "        for i in range(n_deep_layers):\n",
    "            if i == n_deep_layers - 1:\n",
    "                dnn_layers.append(nn.ReLU())\n",
    "                dnn_layers.append(nn.Linear(nhid, n_outputs))\n",
    "            else:\n",
    "                dnn_layers.append(nn.ReLU())\n",
    "                dnn_layers.append(nn.Linear(nhid, nhid))\n",
    "                if dropout:\n",
    "                      dnn_layers.append(nn.Dropout(p=dropout))\n",
    "        self.dnn = nn.Sequential(*dnn_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        hidden_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "        cell_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            hidden_state = hidden_state.to(device)\n",
    "            cell_state = cell_state.to(device)\n",
    "        \n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "        x, h = self.lstm(x, self.hidden)\n",
    "        x = self.dropout(x.contiguous().view(x.shape[0], -1)) \n",
    "        x = self.fc1(x)\n",
    "        return self.dnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhid = 20\n",
    "n_dnn_layers = 2\n",
    "nout = 1\n",
    "sequence_len = 180 \n",
    "ninp = 2\n",
    "\n",
    "USE_CUDA = False\n",
    "device = 'cpu'\n",
    "\n",
    "model = LSTMForecaster(ninp, nhid, nout, sequence_len, n_deep_layers=n_dnn_layers, use_cuda=USE_CUDA).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(tr, va):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(tr, label='train')\n",
    "    ax.plot(va, label='validation')\n",
    "    plt.show()\n",
    "t_losses, v_losses = [], []\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, valid_loss = 0.0, 0.0\n",
    " \n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y  = y.squeeze().to(device)\n",
    "        preds = model(x).squeeze()\n",
    "        loss = criterion(preds, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss = train_loss / len(trainloader)\n",
    "    t_losses.append(epoch_loss)\n",
    "    model.eval()\n",
    "    for x, y in testloader:\n",
    "        with torch.no_grad():\n",
    "            x, y = x.to(device), y.squeeze().to(device)\n",
    "            preds = model(x).squeeze()\n",
    "            error = criterion(preds, y)\n",
    "        valid_loss += error.item()\n",
    "    valid_loss = valid_loss / len(testloader)\n",
    "    v_losses.append(valid_loss)\n",
    "      \n",
    "    print(f'{epoch} - train: {epoch_loss}, valid: {valid_loss}')\n",
    "plot_losses(t_losses, v_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
